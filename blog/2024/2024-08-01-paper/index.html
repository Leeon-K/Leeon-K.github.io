<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="first-tabs">First tabs</h2> <p>7/11 刚开源的FA3，FA 和 Mamba原作者Tri Dao 团队的作品。 核心贡献 FA在H100这种新架构上只有35%的max Flops利用率，1.5-2.0x的fp16（baseline：FA2）。利用Tensor Cores和TMA进行3个提速的点：</p> <ol> <li>Warp-specialization overlap计算和数据搬运；</li> <li>交错（异步？）block-wise matmul和softmax；</li> <li>解耦FP8低精度的硬件支持。 FAv1 v2 <img src="image.png" alt="alt text"> 之前FA的介绍：https://zhuanlan.zhihu.com/p/668888063 Hopper新特性 H100新特性 WGMMA GPC技术的一个MMA指令，跟之前架构下的MMA指令的最大区别在于，WGMMA支持warp-group的能力。之前的MMA指令都是基于单warp的，这项技术基于Hopper的Thread blocks cluster （Graphics Processing Clusters（GPC））技术和distributed shared memory。</li> </ol> <p><img src="image-1.png" alt="alt text">Vollta~Ampere架构，TensorCore指令就是WMMA令人头秃的cudaTensorCoreGemm详解_wmma cuda-CSDN博客； TMA 异步执行（Tensor Memory Accelerator）</p> <p>FP8</p> <p>FA3</p> <p>疑问： [] FA3核心在于基于Hopper的新特性做实现上的优化，但是Hopper 22年就出了，之前这么长时间都没有基于H系列卡的优化吗？ Ref https://zhuanlan.zhihu.com/p/708409249 https://tridao.me/blog/2024/flash3/ 官方博客 https://tridao.me/publications/flash3/flash3.pdf paper</p> <p>RingAttention</p> <p>https://github.com/zhuzilin/ring-flash-attention</p> </body></html>